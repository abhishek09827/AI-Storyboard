{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Ai-story-board-fine-tune"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LoRA Fine-Tuning of SDXL for Studio Ghibli Style\n",
        "\n",
        "This notebook provides a complete workflow for fine-tuning a **Stable Diffusion XL (SDXL)** model to generate images in a specific artistic style using **Low-Rank Adaptation (LoRA)**. The goal is to teach the model the \"Studio Ghibli\" aesthetic using a custom dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### Core Process\n",
        "\n",
        "1.  **Setup & Installation**\n",
        "    * Installs essential libraries like `diffusers`, `transformers`, `peft`, `bitsandbytes`, and `accelerate` for distributed training.\n",
        "    * Downloads a specialized script for training a Dreambooth LoRA on SDXL.\n",
        "\n",
        "2.  **Data Preparation**\n",
        "    * Loads the \"Nechintosh/ghibli\" image dataset from the Hugging Face Hub.\n",
        "    * Prepares the training data by saving images locally and creating a `metadata.jsonl` file.\n",
        "    * Each image caption in the metadata is prepended with the trigger phrase \"**Studio Ghibli**\" to associate the style with the prompt.\n",
        "\n",
        "3.  **LoRA Training**\n",
        "    * Uses `accelerate` to launch the training script for efficient, distributed training on a GPU.\n",
        "    * Key training parameters are configured, including the base SDXL model, data directories, learning rate, batch size, and resolution.\n",
        "    * The training progress and metrics are logged to **Weights & Biases (wandb)** for monitoring.\n",
        "\n",
        "4.  **Inference and Image Generation**\n",
        "    * Loads the base SDXL model pipeline.\n",
        "    * Applies the newly trained LoRA weights to the pipeline.\n",
        "    * Demonstrates how to generate a new image by providing a prompt that includes the \"**Studio Ghibli**\" trigger, successfully creating an image in the fine-tuned style."
      ],
      "metadata": {
        "id": "JGqJXzBJXn9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required libraries with version specifications\n"
      ],
      "metadata": {
        "id": "A9SZ3-NuWYjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U peft==0.15.1 bitsandbytes transformers accelerate git+https://github.com/huggingface/diffusers.git datasets wandb -q"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T19:01:33.2145Z",
          "iopub.execute_input": "2025-05-20T19:01:33.214806Z",
          "iopub.status.idle": "2025-05-20T19:01:36.370975Z",
          "shell.execute_reply.started": "2025-05-20T19:01:33.21478Z",
          "shell.execute_reply": "2025-05-20T19:01:36.370234Z"
        },
        "id": "zrH4YicOU5rQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the training script for Dreambooth LoRA SDXL\n"
      ],
      "metadata": {
        "id": "Z1144UCQWb5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/AnKiTu03/dreambot/refs/heads/main/train_dreambooth_lora_sdxl.py"
      ],
      "metadata": {
        "id": "J2JVWtheLO6M",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T19:01:52.759964Z",
          "iopub.execute_input": "2025-05-20T19:01:52.760185Z",
          "iopub.status.idle": "2025-05-20T19:01:53.145625Z",
          "shell.execute_reply.started": "2025-05-20T19:01:52.760164Z",
          "shell.execute_reply": "2025-05-20T19:01:53.144957Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries for data handling, visualization, and system operations\n"
      ],
      "metadata": {
        "id": "z1MrrfRlWeEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "import json\n",
        "import locale\n",
        "import wandb"
      ],
      "metadata": {
        "id": "JkoYplzfLS5C",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T18:53:26.450291Z",
          "iopub.execute_input": "2025-05-20T18:53:26.45061Z",
          "iopub.status.idle": "2025-05-20T18:53:29.288164Z",
          "shell.execute_reply.started": "2025-05-20T18:53:26.450578Z",
          "shell.execute_reply": "2025-05-20T18:53:29.287652Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log in to Wandb (Weights & Biases) for experiment tracking\n",
        "### Replace \" \" with your actual Wandb API key"
      ],
      "metadata": {
        "id": "NIN0c5XhWgTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key=\"\")"
      ],
      "metadata": {
        "id": "usGKk7JgV1Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the specified dataset from the Hugging Face Hub\n"
      ],
      "metadata": {
        "id": "oZ9by6cBWnR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"Nechintosh/ghibli\", streaming=True)"
      ],
      "metadata": {
        "id": "GzloXuJKLifs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T18:53:29.289171Z",
          "iopub.execute_input": "2025-05-20T18:53:29.28953Z",
          "iopub.status.idle": "2025-05-20T18:53:35.910344Z",
          "shell.execute_reply.started": "2025-05-20T18:53:29.289502Z",
          "shell.execute_reply": "2025-05-20T18:53:35.909807Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save dataset images and create a metadata file in JSON Lines format\n"
      ],
      "metadata": {
        "id": "0q0N57_uW1Zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "local_data_dir = \"./ghibli_training_data\"\n",
        "os.makedirs(local_data_dir, exist_ok=True)\n",
        "\n",
        "metadata_path = os.path.join(local_data_dir, \"metadata.jsonl\")\n",
        "\n",
        "with open(f'{local_data_dir}metadata.jsonl', \"w\") as outfile:\n",
        "    for i, example in enumerate(ds[\"train\"]):\n",
        "        if i <250:\n",
        "            image = example[\"image\"]\n",
        "            text =  example[\"caption\"]\n",
        "\n",
        "            # Save the image\n",
        "            image_filename = f\"image_{i:04d}.png\"\n",
        "            image_path = os.path.join(local_data_dir, image_filename)\n",
        "            image.save(image_path)\n",
        "\n",
        "            # Create the metadata entry\n",
        "            entry = {\"file_name\": image_filename, \"prompt\": text}\n",
        "\n",
        "            # Write the metadata entry to the JSON Lines file\n",
        "            json.dump(entry, outfile)\n",
        "            outfile.write('\\n')\n",
        "\n",
        "print(f\"Saved dataset to {local_data_dir} with metadata.jsonl\")"
      ],
      "metadata": {
        "id": "AnDGGewv0Umn",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T18:53:43.638137Z",
          "iopub.execute_input": "2025-05-20T18:53:43.638405Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a directory for the output of the LoRA training\n"
      ],
      "metadata": {
        "id": "ZGTn_vH5W3Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /kaggle/working/ghibli_LoRA\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T19:00:52.57645Z",
          "iopub.execute_input": "2025-05-20T19:00:52.576753Z",
          "iopub.status.idle": "2025-05-20T19:00:52.709053Z",
          "shell.execute_reply.started": "2025-05-20T19:00:52.576728Z",
          "shell.execute_reply": "2025-05-20T19:00:52.708055Z"
        },
        "id": "_faHPUAhU5rT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read, modify, and collect the updated entries\n"
      ],
      "metadata": {
        "id": "9zXgKSh9W6ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_path = \"/kaggle/working/ghibli_training_datametadata.jsonl\"\n",
        "updated_lines = []\n",
        "\n",
        "# Read, modify, and collect the updated entries\n",
        "with open(metadata_path, \"r\") as infile:\n",
        "    for line in infile:\n",
        "        entry = json.loads(line)\n",
        "        entry[\"prompt\"] = \"Studio Ghibli \" + entry[\"prompt\"]\n",
        "        updated_lines.append(entry)\n",
        "\n",
        "# Overwrite the original file with updated captions\n",
        "with open(metadata_path, \"w\") as outfile:\n",
        "    for entry in updated_lines:\n",
        "        json.dump(entry, outfile)\n",
        "        outfile.write('\\n')\n",
        "\n",
        "print(\"Updated captions in metadata.jsonl with 'Studio Ghibli' prefix.\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T19:00:43.96894Z",
          "iopub.execute_input": "2025-05-20T19:00:43.969623Z",
          "iopub.status.idle": "2025-05-20T19:00:43.978309Z",
          "shell.execute_reply.started": "2025-05-20T19:00:43.969598Z",
          "shell.execute_reply": "2025-05-20T19:00:43.977763Z"
        },
        "id": "78kG7oomU5rT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set locale encoding and configure accelerate\n"
      ],
      "metadata": {
        "id": "yUp82VRQW-Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!accelerate config default"
      ],
      "metadata": {
        "id": "iQfmPx6QPh_U",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T19:02:38.868139Z",
          "iopub.execute_input": "2025-05-20T19:02:38.868459Z",
          "iopub.status.idle": "2025-05-20T19:02:45.608917Z",
          "shell.execute_reply.started": "2025-05-20T19:02:38.868433Z",
          "shell.execute_reply": "2025-05-20T19:02:45.607948Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Launch the Dreambooth LoRA training script with specified parameters\n"
      ],
      "metadata": {
        "id": "ZNdmIGVhXAcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env bash\n",
        "!accelerate launch train_dreambooth_lora_sdxl.py \\\n",
        "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
        "  --pretrained_vae_model_name_or_path=\"madebyollin/sdxl-vae-fp16-fix\" \\\n",
        "  --instance_data_dir={local_data_dir}\\\n",
        "  --output_dir=\"/kaggle/working/ghibli_LoRA\" \\\n",
        "  --caption_column=\"prompt\"\\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --instance_prompt=\"Studio Ghibli\" \\\n",
        "  --resolution=1024 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=3 \\\n",
        "  --gradient_checkpointing \\\n",
        "  --learning_rate=1e-4 \\\n",
        "  --snr_gamma=5.0 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --max_train_steps=300 \\\n",
        "  --checkpointing_steps=717 \\\n",
        "  --seed=\"0\"\\\n",
        "  --report_to=wandb"
      ],
      "metadata": {
        "id": "MJPbcli-PxfK",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T19:03:13.242129Z",
          "iopub.execute_input": "2025-05-20T19:03:13.242971Z",
          "iopub.status.idle": "2025-05-20T19:51:53.153911Z",
          "shell.execute_reply.started": "2025-05-20T19:03:13.242943Z",
          "shell.execute_reply": "2025-05-20T19:51:53.152911Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the trained LoRA model and the base Stable Diffusion XL pipeline\n"
      ],
      "metadata": {
        "id": "bQ3CsnmfXDO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import DiffusionPipeline, AutoencoderKL\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True\n",
        ")\n",
        "pipe.load_lora_weights(\"/content/pytorch_lora_weights.safetensors\")\n",
        "_ = pipe.to(\"cuda\")"
      ],
      "metadata": {
        "id": "PY9zwziEQcWL",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate an image using the trained LoRA model and a specific prompt\n"
      ],
      "metadata": {
        "id": "L2I-gdopXHEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Studio Ghibli animation still of futuristic vibrant city, lively diverse crowd, lush green spaces, animated sparkles, joyous atmosphere, vivid colors, sense of harmony, ultra-detailed concept art, by Studio Ghibli\"\n",
        "\n",
        "image = pipe(prompt=prompt, num_inference_steps=50).images[0]\n",
        "image"
      ],
      "metadata": {
        "id": "-5CwujHjUQ6w",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}